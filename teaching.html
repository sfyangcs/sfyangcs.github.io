<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Teaching</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="research.html">Research</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
<div class="menu-item"><a href="group.html">Group</a></div>
<div class="menu-item"><a href="teaching.html" class="current">Teaching</a></div>
<div class="menu-item"><a href="misc.html">Miscellaneous</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Teaching</h1>
</div>

<h2>B58A1070：自动控制原理</h2>
<ol>
<li><p><b>考核</b>：平时考查与期末考查相结合。
<ul>
<li>平时成绩(30%)： 考勤与作业</li>
<li>综合考查(70%)： 半开卷测验</li>
</ul>
</p></li>
 
<li><p><b>参考书目</b>：
<ul>
<li>梅晓榕，自动控制原理，科学出版社，2002</li>
</ul>
</p></li>
</ol>


<h2>B58A1060: Reinforcement Learning</h2>
<ol>
<li><p><b>Assessment</b>：
<ul>
<li>Homework: 30%</li>
<li>Course Project: 70%</li>
</ul>
</p></li>
 
<li><p><b>References</b>：
<ul>
<li>Reinforcement Learning: An Introduction, 2nd Edition, Richard S. Sutton, Andrew G. Barto, MIT Press, 2018.</li>
</ul>
</p></li>
</ol>


<h2>DB009135: Optimization, Game Theory and Learning</h2>
<ol>
<li><p><b>Assessment</b>： 
<ul>
	<li>Class participation: 20%</li>
	<li>Homework: 40%</li>
	<li>Course project: 40%</li>
</ul>
</p></li>

<li><p><b>Topics</b>：
<ul>
<li><b>Optimization theory and algorithms</b>: gradient descent algorithms, proximal algorithms, mirror descent, primal-dual methods, accelerated methods, etc.</li>
<li><b>Game theory and algorithms</b>: minimax optimization, Nash equilibrium seeking.</li>
<li><b>Optimization in learning</b>: optimization problems or game problems arisen in machine learning (such as supervised learning, reinforcement learning, federated learning, etc.), stochastic gradient descent, variance reduced methods.</li>
<li><b>Other topics (Option)</b>: security and privacy protection in optimization or learning algorithms, learning to optimize (an emerging approach that leverages machine learning to develop optimization methods).</li>
</ul>
</p></li>
 
<li><p><b>References</b>：
<ul>
<li>S. Boyd and L. Vandenberghe, Convex Optimization, 2004.</li>
<li>N. Parikh and S. Boyd, Proximal algorithms, Foundations and Trends in Optimization, vol. 1, no. 3, pp. 123–231, 2013.</li>
<li>S. Bubeck, Convex optimization: Algorithms and complexity, Foundations and Trends in Machine Learning, vol. 8, no. 3–4, pp. 231–357, 2015.</li>
<li>Dimitri P. Bertsekas, Nonlinear Programming, 3rd edition, 2016.</li>
<li>R. Sun, Optimization for deep learning: An overview, Journal of the Operations Research Society of China, vol. 8, no. 2, pp. 249–294, 2020.</li>
<li>L. Bottou, F. E. Curtis, and J. Nocedal, Optimization methods for large-scale machine learning, SIAM Review, vol. 60, no. 2, pp. 223–311, 2018.</li>
<li>R. M. Gower, M. Schmidt, F. Bach, and P. Richtarik, Variance-reduced methods for machine learning, Proceedings of the IEEE, vol. 108, no. 11, pp. 1968–1983, 2020.</li>
<li>T. Li, G. Peng, Q. Zhu, and T. Basar, The confluence of networks, games, and learning a game-theoretic framework for multiagent decision making over networks, IEEE Control Systems, pp. 35–67, 2022.</li>
<li>T. Chen et al., Learning to Optimize: A Primer and A Benchmark, Journal of Machine Learning Research, vol. 23, pp. 1–59, 2022.</li>
<li>...... (comming soon)</li>
</ul>
</p></li>
</ol>

<p><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /></p>
</td>
</tr>
</table>
</body>
</html>
